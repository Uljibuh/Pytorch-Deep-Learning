{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-12T15:51:40.799581Z","iopub.execute_input":"2022-02-12T15:51:40.799844Z","iopub.status.idle":"2022-02-12T15:51:40.809635Z","shell.execute_reply.started":"2022-02-12T15:51:40.799816Z","shell.execute_reply":"2022-02-12T15:51:40.808755Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n","metadata":{"execution":{"iopub.status.busy":"2022-02-12T15:51:43.617486Z","iopub.execute_input":"2022-02-12T15:51:43.618058Z","iopub.status.idle":"2022-02-12T15:51:43.622463Z","shell.execute_reply.started":"2022-02-12T15:51:43.618009Z","shell.execute_reply":"2022-02-12T15:51:43.621718Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Import Libraries\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nfrom sklearn.model_selection import train_test_split\nfrom torch.utils.data import DataLoader, TensorDataset","metadata":{"execution":{"iopub.status.busy":"2022-02-12T15:51:46.387401Z","iopub.execute_input":"2022-02-12T15:51:46.387906Z","iopub.status.idle":"2022-02-12T15:51:48.558400Z","shell.execute_reply.started":"2022-02-12T15:51:46.387852Z","shell.execute_reply":"2022-02-12T15:51:48.557538Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Prepare Dataset\n# load data\ntrain = pd.read_csv(\"/kaggle/input/digit-recognizer/train.csv\",dtype = np.float32)\n\n# split data into features(pixels) and labels(numbers from 0 to 9)\ntargets_numpy = train.label.values\nfeatures_numpy = train.loc[:,train.columns != \"label\"].values/255 # normalization\n\n# train test split. Size of train data is 80% and size of test data is 20%. \nfeatures_train, features_test, targets_train, targets_test = train_test_split(features_numpy,\n                                                                             targets_numpy,\n                                                                             test_size = 0.2,\n                                                                             random_state = 42) \n\n# create feature and targets tensor for train set. As you remember we need variable to accumulate gradients. Therefore first we create tensor, then we will create variable\nfeaturesTrain = torch.from_numpy(features_train)\ntargetsTrain = torch.from_numpy(targets_train).type(torch.LongTensor) # data type is long\n\n# create feature and targets tensor for test set.\nfeaturesTest = torch.from_numpy(features_test)\ntargetsTest = torch.from_numpy(targets_test).type(torch.LongTensor) # data type is long\n\n# batch_size, epoch and iteration\nbatch_size = 100\nn_iters = 3000\nnum_epochs = n_iters / (len(features_train) / batch_size)\nnum_epochs = int(num_epochs)\n\n# Pytorch train and test sets\ntrain = TensorDataset(featuresTrain,targetsTrain)\ntest = TensorDataset(featuresTest,targetsTest)\n\n# data loader\ntrain_loader = DataLoader(train, batch_size = batch_size, shuffle = False)\ntest_loader = DataLoader(test, batch_size = batch_size, shuffle = False)\n\n# visualize one of the images in data set\nplt.imshow(features_numpy[8].reshape(28,28))\nplt.axis(\"off\")\nplt.title(str(targets_numpy[10]))\nplt.savefig('graph.png')\nplt.show()\n\nprint(len(train_loader.dataset))\nprint(len(test_loader.dataset))","metadata":{"execution":{"iopub.status.busy":"2022-02-12T16:49:42.718877Z","iopub.execute_input":"2022-02-12T16:49:42.719146Z","iopub.status.idle":"2022-02-12T16:49:45.721413Z","shell.execute_reply.started":"2022-02-12T16:49:42.719118Z","shell.execute_reply":"2022-02-12T16:49:45.720248Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"# Create RNN Model\nclass RNNModel(nn.Module):\n    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n        super(RNNModel, self).__init__()\n        \n        # Number of hidden dimensions\n        self.hidden_dim = hidden_dim\n        \n        # Number of hidden layers\n        self.layer_dim = layer_dim\n        \n        # RNN\n        self.rnn = nn.RNN(input_dim, hidden_dim, layer_dim, batch_first=True, nonlinearity='relu')\n        \n        # Readout layer\n        self.fc = nn.Linear(hidden_dim, output_dim)\n    \n    def forward(self, x):\n        \n        # Initialize hidden state with zeros\n        h0 = Variable(torch.zeros(self.layer_dim, x.size(0), self.hidden_dim))\n            \n        # One time step\n        out, hn = self.rnn(x, h0)\n        out = self.fc(out[:, -1, :]) \n        return out\n\n# batch_size, epoch and iteration\nbatch_size = 100\nn_iters = 4000\nnum_epochs = n_iters / (len(features_train) / batch_size)\nnum_epochs = int(num_epochs)\n\n# Pytorch train and test sets\ntrain = TensorDataset(featuresTrain,targetsTrain)\ntest = TensorDataset(featuresTest,targetsTest)\n\n# data loader\ntrain_loader = DataLoader(train, batch_size = batch_size, shuffle = False)\ntest_loader = DataLoader(test, batch_size = batch_size, shuffle = False)\n    \n# Create RNN\ninput_dim = 28    # input dimension\nhidden_dim = 100  # hidden layer dimension\nlayer_dim = 1     # number of hidden layers\noutput_dim = 10   # output dimension\n\nmodel = RNNModel(input_dim, hidden_dim, layer_dim, output_dim)\n\n# Cross Entropy Loss \nerror = nn.CrossEntropyLoss()\n\n# SGD Optimizer\nlearning_rate = 0.05\noptimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)","metadata":{"execution":{"iopub.status.busy":"2022-02-12T16:49:48.766233Z","iopub.execute_input":"2022-02-12T16:49:48.766764Z","iopub.status.idle":"2022-02-12T16:49:48.776751Z","shell.execute_reply.started":"2022-02-12T16:49:48.766729Z","shell.execute_reply":"2022-02-12T16:49:48.776154Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"seq_dim = 28  \nloss_list = []\niteration_list = []\naccuracy_list = []\ncount = 0\nfor epoch in range(num_epochs):\n    for i, (images, labels) in enumerate(train_loader):\n\n        train  = Variable(images.view(-1, seq_dim, input_dim))\n        labels = Variable(labels )\n            \n        # Clear gradients\n        optimizer.zero_grad()\n        \n        # Forward propagation\n        outputs = model(train)\n        \n        # Calculate softmax and ross entropy loss\n        loss = error(outputs, labels)\n        \n        # Calculating gradients\n        loss.backward()\n        \n        # Update parameters\n        optimizer.step()\n        \n        count += 1\n        \n        if count % 250 == 0:\n            # Calculate Accuracy         \n            correct = 0\n            total = 0\n            # Iterate through test dataset\n            for images, labels in test_loader:\n                images = Variable(images.view(-1, seq_dim, input_dim))\n                \n                # Forward propagation\n                outputs = model(images)\n                \n                # Get predictions from the maximum value\n                predicted = torch.max(outputs.data, 1)[1]\n                \n                # Total number of labels\n                total += labels.size(0)\n                \n                correct += (predicted == labels).sum()\n            \n            accuracy = 100 * correct / float(total)\n            \n            # store loss and iteration\n            loss_list.append(loss.data)\n            iteration_list.append(count)\n            accuracy_list.append(accuracy)\n            if count % 500 == 0:\n                 #Print Loss\n                print('Iteration: {}  Loss: {}  Accuracy: {} %'.format(count, loss.data.item(), accuracy))\n","metadata":{"execution":{"iopub.status.busy":"2022-02-12T16:49:53.472487Z","iopub.execute_input":"2022-02-12T16:49:53.472813Z","iopub.status.idle":"2022-02-12T16:50:25.495125Z","shell.execute_reply.started":"2022-02-12T16:49:53.472778Z","shell.execute_reply":"2022-02-12T16:50:25.494378Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"# visualization loss \nplt.plot(iteration_list,loss_list)\nplt.xlabel(\"Number of iteration\")\nplt.ylabel(\"loss\")\nplt.title(\"RNN: loss vs number of iteration\")\nplt.show()\n\n# visualization accuracy\nplt.plot(iteration_list,accuracy_list, color=\"red\")\nplt.xlabel(\"number of iteration\")\nplt.ylabel(\"accuracy\")\nplt.title(\"RNN: Accuracy vs Number of iteration\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-12T16:51:00.425711Z","iopub.execute_input":"2022-02-12T16:51:00.425982Z","iopub.status.idle":"2022-02-12T16:51:00.764851Z","shell.execute_reply.started":"2022-02-12T16:51:00.425954Z","shell.execute_reply":"2022-02-12T16:51:00.764216Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":"**LSTM model**","metadata":{}},{"cell_type":"code","source":"class LSTMModel(nn.Module):\n    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n        super(LSTMModel, self).__init__()\n        \n        # hidden dimension\n        self.hidden_dim = hidden_dim\n        \n        # number of hidden layers\n        self.layer_dim = layer_dim\n        \n        #LSTM\n        self.lstm = nn.LSTM(input_dim, hidden_dim, layer_dim, batch_first=True)\n        \n        # readout layer\n        self.fc = nn.Linear(hidden_dim, output_dim)\n        \n    \n    \n    def forward(self, x):\n        # initialize hidden state with zeros\n        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).requires_grad_()\n        \n        # initialize cell state\n        c0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).requires_grad_()\n        \n        # 28 time steps\n        # We need to detach as we are doing truncated backpropagation through time (BPTT)\n        # If we don't, we'll backprop all the way to the start even after going through another batch\n        out, (hn, cn) = self.lstm(x, (h0.detach(), c0.detach()))\n        \n        # Index hidden state of last time step\n        # out.size() --> 100, 28, 100\n        # out[:, -1, :] --> 100, 100 --> just want last time step hidden state\n        \n        out = self.fc(out[:, -1, :])\n        # out.size() --> 100, 10\n        return out\n\ninput_dim = 28\nhidden_dim = 100\nlayer_dim = 1\noutput_dim = 10\nmodel = LSTMModel(input_dim, hidden_dim, layer_dim, output_dim)\n\nerror = nn.CrossEntropyLoss()\n\nlearning_rate = 0.1\noptimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n    \n    \n\n    \n        ","metadata":{"execution":{"iopub.status.busy":"2022-02-12T16:51:30.728108Z","iopub.execute_input":"2022-02-12T16:51:30.728815Z","iopub.status.idle":"2022-02-12T16:51:30.740560Z","shell.execute_reply.started":"2022-02-12T16:51:30.728777Z","shell.execute_reply":"2022-02-12T16:51:30.739600Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"# Number of steps to unroll\nseq_dim = 28  \nloss_list = []\niteration_list = []\naccuracy_list = []\ncount = 0\nfor epoch in range(num_epochs):\n    for i, (images, labels) in enumerate(train_loader):\n        # Load images as a torch tensor with gradient accumulation abilities\n        images = images.view(-1, seq_dim, input_dim).requires_grad_()\n\n        # Clear gradients w.r.t. parameters\n        optimizer.zero_grad()\n\n        # Forward pass to get output/logits\n        # outputs.size 100, 10\n        outputs = model(images)\n\n        # Calculate Loss: softmax --> cross entropy loss\n        loss = error(outputs, labels)\n\n        # Getting gradients\n        loss.backward()\n\n        # Updating parameters\n        optimizer.step()\n\n        count += 1\n\n        if count % 500 == 0:\n            # Calculate Accuracy         \n            correct = 0\n            total = 0\n            for images, labels in test_loader:\n                \n                images = images.view(-1, seq_dim, input_dim)\n\n                # Forward pass only to get logits/output\n                outputs = model(images)\n\n                # Get predictions from the maximum value\n                _, predicted = torch.max(outputs.data, 1)\n\n                # Total number of labels\n                total += labels.size(0)\n\n                # Total correct predictions\n                correct += (predicted == labels).sum()\n\n            accuracy = 100 * correct / total\n            \n            loss_list.append(loss.data.item())\n            iteration_list.append(count)\n            accuracy_list.append(accuracy)\n            \n            # Print Loss\n            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(count, loss.data.item(), accuracy))","metadata":{"execution":{"iopub.status.busy":"2022-02-12T16:51:36.952387Z","iopub.execute_input":"2022-02-12T16:51:36.952994Z","iopub.status.idle":"2022-02-12T16:53:21.218988Z","shell.execute_reply.started":"2022-02-12T16:51:36.952954Z","shell.execute_reply":"2022-02-12T16:53:21.218354Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"# visualization loss \nplt.plot(iteration_list,loss_list)\nplt.xlabel(\"Number of iteration\")\nplt.ylabel(\"Loss\")\nplt.title(\"LSTM: Loss vs Number of iteration\")\nplt.show()\n\n# visualization accuracy \nplt.plot(iteration_list,accuracy_list,color = \"red\")\nplt.xlabel(\"Number of iteration\")\nplt.ylabel(\"Accuracy\")\nplt.title(\"LSTM: Accuracy vs Number of iteration\")\nplt.savefig('graph.png')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-12T16:54:08.981085Z","iopub.execute_input":"2022-02-12T16:54:08.981854Z","iopub.status.idle":"2022-02-12T16:54:09.388256Z","shell.execute_reply.started":"2022-02-12T16:54:08.981817Z","shell.execute_reply":"2022-02-12T16:54:09.387299Z"},"trusted":true},"execution_count":33,"outputs":[]}]}