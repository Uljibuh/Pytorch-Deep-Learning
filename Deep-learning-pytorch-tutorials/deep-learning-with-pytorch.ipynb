{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-02T16:07:23.048767Z","iopub.execute_input":"2022-03-02T16:07:23.049895Z","iopub.status.idle":"2022-03-02T16:07:23.061405Z","shell.execute_reply.started":"2022-03-02T16:07:23.049848Z","shell.execute_reply":"2022-03-02T16:07:23.060680Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport warnings\n\n# filter warning\nwarnings.filterwarnings('ignore')\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))","metadata":{"execution":{"iopub.status.busy":"2022-03-02T16:07:23.063428Z","iopub.execute_input":"2022-03-02T16:07:23.063954Z","iopub.status.idle":"2022-03-02T16:07:23.103465Z","shell.execute_reply.started":"2022-03-02T16:07:23.063919Z","shell.execute_reply":"2022-03-02T16:07:23.102579Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.\n","metadata":{"execution":{"iopub.status.busy":"2022-03-02T16:07:23.104916Z","iopub.execute_input":"2022-03-02T16:07:23.105746Z","iopub.status.idle":"2022-03-02T16:07:23.112026Z","shell.execute_reply.started":"2022-03-02T16:07:23.105703Z","shell.execute_reply":"2022-03-02T16:07:23.111399Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"# import numpy library\nimport numpy as np\n\n# numpy array\narray = [[1,2,3],[4,5,6]]\nfirst_array = np.array(array) # 2x3 array\nprint(\"Array Type: {}\".format(type(first_array))) # type\nprint(\"Array Shape: {}\".format(np.shape(first_array))) # shape\nprint(first_array)","metadata":{"execution":{"iopub.status.busy":"2022-03-02T16:07:23.113048Z","iopub.execute_input":"2022-03-02T16:07:23.113979Z","iopub.status.idle":"2022-03-02T16:07:23.127137Z","shell.execute_reply.started":"2022-03-02T16:07:23.113938Z","shell.execute_reply":"2022-03-02T16:07:23.126134Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"import torch\n\ntensor = torch.Tensor(array)\nprint(\"array type: {}\".format(tensor.type))\nprint(\"array shape: {}\".format(tensor.shape))\nprint(tensor)","metadata":{"execution":{"iopub.status.busy":"2022-03-02T16:07:23.129721Z","iopub.execute_input":"2022-03-02T16:07:23.130996Z","iopub.status.idle":"2022-03-02T16:07:23.146520Z","shell.execute_reply.started":"2022-03-02T16:07:23.130947Z","shell.execute_reply":"2022-03-02T16:07:23.145468Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"# numpy ones\nprint(\"Numpy {}\\n\".format(np.ones((2,3))))\n\n#pytorch ones\nprint(torch.ones((2,3)))","metadata":{"execution":{"iopub.status.busy":"2022-03-02T16:07:23.148497Z","iopub.execute_input":"2022-03-02T16:07:23.148914Z","iopub.status.idle":"2022-03-02T16:07:23.159621Z","shell.execute_reply.started":"2022-03-02T16:07:23.148878Z","shell.execute_reply":"2022-03-02T16:07:23.158696Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"# numpy random\nprint(\"Numpy {}\\n\".format(np.random.rand(2,3)))\n\n# pytorch random\nprint(torch.rand(2,3))","metadata":{"execution":{"iopub.status.busy":"2022-03-02T16:07:23.161505Z","iopub.execute_input":"2022-03-02T16:07:23.162027Z","iopub.status.idle":"2022-03-02T16:07:23.172339Z","shell.execute_reply.started":"2022-03-02T16:07:23.161982Z","shell.execute_reply":"2022-03-02T16:07:23.171558Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"# random numpy array\narray = np.random.rand(2,2)\nprint(\"{} {}\\n\".format(type(array),array))\n\n# from numpy to tensor\nfrom_numpy_to_tensor = torch.from_numpy(array)\nprint(\"{}\\n\".format(from_numpy_to_tensor))\n\n# from tensor to numpy\ntensor = from_numpy_to_tensor\nfrom_tensor_to_numpy = tensor.numpy()\nprint(\"{} {}\\n\".format(type(from_tensor_to_numpy),from_tensor_to_numpy))","metadata":{"execution":{"iopub.status.busy":"2022-03-02T16:07:23.173932Z","iopub.execute_input":"2022-03-02T16:07:23.174731Z","iopub.status.idle":"2022-03-02T16:07:23.190198Z","shell.execute_reply.started":"2022-03-02T16:07:23.174693Z","shell.execute_reply":"2022-03-02T16:07:23.189167Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"# create tensor\ntensor = torch.ones(3,3)\nprint(\"\\n\",tensor)\n\n# resize\nprint(\"{}{}\\n\".format(tensor.view(9).shape,tensor.view(9)))\n\n# addition\nprint(\"addition: {}\\n\".format(torch.add(tensor,tensor)))\n\n# subtraction\nprint(\"Subtraction: {}\\n\".format(tensor.sub(2)))\n\n# element wise multiplication\nprint(\"element wise multiplication: {}\\n\".format(torch.mul(tensor,tensor)))\n\n# element wise division\nprint(\"element wise division: {}\\n\".format(torch.div(tensor,4)))\n\n# mean \ntensor = torch.Tensor([1,2,3,4,5])\nprint(\"mean: {}\".format(tensor.mean()))\n\n#standard deviation\nprint(\"std: {}\".format(tensor.std()))","metadata":{"execution":{"iopub.status.busy":"2022-03-02T16:07:23.191795Z","iopub.execute_input":"2022-03-02T16:07:23.192601Z","iopub.status.idle":"2022-03-02T16:07:23.207705Z","shell.execute_reply.started":"2022-03-02T16:07:23.192560Z","shell.execute_reply":"2022-03-02T16:07:23.206778Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"# variables accumulates gradients\n\n# import variable from pytorch library\nfrom torch.autograd import Variable\n\n# define variable\nvar = Variable(torch.ones(3), requires_grad = True)\nvar","metadata":{"execution":{"iopub.status.busy":"2022-03-02T16:07:23.209378Z","iopub.execute_input":"2022-03-02T16:07:23.210380Z","iopub.status.idle":"2022-03-02T16:07:23.221030Z","shell.execute_reply.started":"2022-03-02T16:07:23.210309Z","shell.execute_reply":"2022-03-02T16:07:23.219956Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"# lets make basic backward propagation\n# we have an equation that is y = x^2\narray = [2,4]\ntensor = torch.Tensor(array)\n\nx = Variable(tensor, requires_grad = True)\ny = x**2\nprint(\"y = \",y)\n\n# recap o equation o = 1/2*sum(y)\no = (1/2)*sum(y)\nprint(\"o = \", o)\n\n# backward\no.backward()\n\nprint(\"gradients: \", x.grad)","metadata":{"execution":{"iopub.status.busy":"2022-03-02T16:07:23.222804Z","iopub.execute_input":"2022-03-02T16:07:23.223473Z","iopub.status.idle":"2022-03-02T16:07:23.235238Z","shell.execute_reply.started":"2022-03-02T16:07:23.223437Z","shell.execute_reply":"2022-03-02T16:07:23.234419Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"markdown","source":"# Linear Regression\n","metadata":{}},{"cell_type":"code","source":"# As a car company we collect this data from previous selling\n# lets define car prices\ncar_prices_array = [3,4,5,6,7,8,9]\ncar_price_np = np.array(car_prices_array,dtype=np.float32)\ncar_price_np = car_price_np.reshape(-1,1)\ncar_price_tensor = Variable(torch.from_numpy(car_price_np))\n\n# lets define number of car sell\nnumber_of_car_sell_array = [7.5, 7, 6.5, 6.0, 5.5, 5.0, 4.5]\nnumber_of_car_sell_np = np.array(number_of_car_sell_array, dtype=np.float32)\nnumber_of_car_sell_np = number_of_car_sell_np.reshape(-1,1)\nnumber_of_car_sell_tensor = Variable(torch.from_numpy(number_of_car_sell_np))\n\n# let visualize our data\nimport matplotlib.pyplot as plt\nplt.scatter(car_prices_array,number_of_car_sell_array)\nplt.xlabel(\"Car price $\")\nplt.ylabel(\"number of car sell\")\nplt.title(\"car price vs number of car sell\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-02T16:07:23.239100Z","iopub.execute_input":"2022-03-02T16:07:23.240426Z","iopub.status.idle":"2022-03-02T16:07:23.457154Z","shell.execute_reply.started":"2022-03-02T16:07:23.240283Z","shell.execute_reply":"2022-03-02T16:07:23.456014Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"# linear regression with pytorch\n\n#libraries\nimport torch \nfrom torch.autograd import Variable\nimport torch.nn as nn\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# create class\nclass LinearRegression(nn.Module):\n    def __init__(self,input_size,out_size):\n        # super function. It inherits from nn.Module and we can access everythink in nn.Module\n        super(LinearRegression,self).__init__()\n        # linear function\n        self.linear = nn.Linear(input_dim,output_dim)\n    \n    def forward(self,x):\n        return self.linear(x)\n    \n# define model\ninput_dim = 1\noutput_dim = 1\n# input and output size are 1\nmodel = LinearRegression(input_dim,output_dim)\n\n#MSE\nmse = nn.MSELoss()\n\n# optimization (find parameters that minimize error)\nlearning_rate = 0.02\noptimizer = torch.optim.SGD(model.parameters(),lr = learning_rate)\n\n#train model\nloss_list = []\niteration_number = 500\nfor iteration in range(iteration_number):\n    \n    # optimization \n    optimizer.zero_grad()\n    \n    # forward to get output\n    results = model(car_price_tensor)\n    \n    #caculate loss\n    loss = mse(results, number_of_car_sell_tensor)\n    \n    # backward propagation\n    loss.backward()\n    \n    # updating parameters\n    optimizer.step()\n    \n    # store loss\n    loss_list.append(loss.data)\n    \n    # print loss\n    if(iteration % 50 == 0):\n        print('epoch {}, loss{}'.format(iteration, loss.data))\n        \n        \n        ","metadata":{"execution":{"iopub.status.busy":"2022-03-02T16:07:23.458728Z","iopub.execute_input":"2022-03-02T16:07:23.458994Z","iopub.status.idle":"2022-03-02T16:07:23.622226Z","shell.execute_reply.started":"2022-03-02T16:07:23.458962Z","shell.execute_reply":"2022-03-02T16:07:23.620909Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"# plot loss \nplt.plot(range(iteration_number),loss_list)\nplt.xlabel(\"number of iterations\")\nplt.ylabel(\"loss\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-02T16:07:23.624844Z","iopub.execute_input":"2022-03-02T16:07:23.625182Z","iopub.status.idle":"2022-03-02T16:07:23.820899Z","shell.execute_reply.started":"2022-03-02T16:07:23.625138Z","shell.execute_reply":"2022-03-02T16:07:23.819962Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"# predict our car price \npredicted = model(car_price_tensor).data.numpy()\nplt.scatter(car_prices_array,number_of_car_sell_array,label=\"original data\", color=\"red\")\n\nplt.scatter(car_prices_array,predicted,label=\"predicted data\", color=\"blue\")\n\nplt.legend()\nplt.xlabel(\"car price $\")\nplt.ylabel(\"number of car sell\")\nplt.title(\"original vs predicted values\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-02T16:07:23.822227Z","iopub.execute_input":"2022-03-02T16:07:23.822701Z","iopub.status.idle":"2022-03-02T16:07:24.082917Z","shell.execute_reply.started":"2022-03-02T16:07:23.822668Z","shell.execute_reply":"2022-03-02T16:07:24.081905Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"markdown","source":"# Logistic Regression","metadata":{}},{"cell_type":"code","source":"# import libraries\nimport torch \nimport torch.nn as nn\nfrom torch.autograd import Variable\nfrom torch.utils.data import DataLoader\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2022-03-02T16:07:24.084334Z","iopub.execute_input":"2022-03-02T16:07:24.084609Z","iopub.status.idle":"2022-03-02T16:07:24.089213Z","shell.execute_reply.started":"2022-03-02T16:07:24.084580Z","shell.execute_reply":"2022-03-02T16:07:24.088600Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"# prepare Dataset\n# load data\ntrain = pd.read_csv(\"/kaggle/input/digit-recognizer/train.csv\", dtype=np.float32)\n\n# split data into features(pixels) and labels(number from 0 to 9)\ntargets_numpy = train.label.values\n#normalization\nfeatures_numpy = train.loc[:,train.columns != \"label\"].values/255\n\n# train test split, size of train data is 80% and size of test data is 20%\nfeatures_train, features_test, targets_train, targets_test = train_test_split(features_numpy, targets_numpy, test_size=0.2, random_state = 42)\n\n# create feature and targets tensor for train set. As you remember we need variable to accumulate gradients. Therefore first we create tensor, then we will create variable\nfeaturesTrain = torch.from_numpy(features_train)\ntargetsTrain = torch.from_numpy(targets_train).type(torch.LongTensor)\n\n# create features and targets tensor for test set\nfeaturesTest = torch.from_numpy(features_test)\ntargetsTest = torch.from_numpy(targets_test).type(torch.LongTensor)\n\n# batch_size, epoch and iteration\nbatch_size = 100\nn_iters = 10000\nnum_epochs = n_iters / (len(features_train) / batch_size)\nnum_epochs = int(num_epochs)\n\n# Pytorch train and test sets\ntrain = torch.utils.data.TensorDataset(featuresTrain,targetsTrain)\ntest = torch.utils.data.TensorDataset(featuresTest,targetsTest)\n\n# data loader\ntrain_loader = DataLoader(train, batch_size=batch_size, shuffle=False)\ntest_loader = DataLoader(test, batch_size=batch_size, shuffle=False)\n\n# visualize one of image in dataset\nplt.imshow(features_numpy[10].reshape(28,28))\nplt.axis(\"off\")\nplt.title(str(targets_numpy[10]))\nplt.savefig('gragh.png')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-02T16:07:24.090459Z","iopub.execute_input":"2022-03-02T16:07:24.090680Z","iopub.status.idle":"2022-03-02T16:07:28.173054Z","shell.execute_reply.started":"2022-03-02T16:07:24.090654Z","shell.execute_reply":"2022-03-02T16:07:28.172085Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"# craete logistic regression model\nclass LogisticRegressionModel(nn.Module):\n    def __init__(self, input_dim, output_dim):\n        super(LogisticRegressionModel, self).__init__()\n        #linear part \n        self.linear = nn.Linear(input_dim, output_dim)\n        \n        #logistic function in pytorch is in loss function\n        # So actually we do not forget to put it, it is only at next parts\n    def forward(self, x):\n        out = self.linear(x)\n        return out\n    \n# instantiate model class\ninput_dim = 28*28 # size of image\noutput_dim = 10 # labels 0,1,2,3,4,5,6,7,8,9\n    \n# create logistic regression model\nmodel = LogisticRegressionModel(input_dim, output_dim)\n\n# cross entropy loss\nerror = nn.CrossEntropyLoss()\n\n# SGD optimizer\nlearning_rate = 0.003\noptimizer = torch.optim.SGD(model.parameters(),lr=learning_rate)\n    \n    \n    \n    \n    \n    \n    \n    \n    ","metadata":{"execution":{"iopub.status.busy":"2022-03-02T16:07:28.175292Z","iopub.execute_input":"2022-03-02T16:07:28.175759Z","iopub.status.idle":"2022-03-02T16:07:28.188608Z","shell.execute_reply.started":"2022-03-02T16:07:28.175705Z","shell.execute_reply":"2022-03-02T16:07:28.187570Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"# tarining the model\ncount = 0\nloss_list = []\niteration_list = []\nfor epoch in range(num_epochs):\n    for i, (images, labels) in enumerate(train_loader):\n        \n        #define variables\n        train = Variable(images.view(-1, 28*28))\n        lebels = Variable(labels)\n        \n        #clear gradients\n        optimizer.zero_grad()\n        \n        # forward propagation\n        outputs = model(train)\n        \n        # calculate softmax and cross entropy loss\n        loss = error(outputs, labels)\n        \n        # calculate gradients\n        loss.backward()\n        \n        #update parameters\n        optimizer.step()\n        \n        count += 1\n        \n        # prediction\n        if count % 50 == 0:\n            #calculate accuracy\n            correct = 0\n            total = 0\n            \n            # predict test dataset\n            for image, labels in test_loader:\n                test = Variable(image.view(-1, 28*28))\n                \n                # forward propagation\n                outputs = model(test)\n                \n                # get prediction from the maximum value\n                predicted = torch.max(outputs.data, 1)[1]\n                \n                #total number of labels\n                total += len(labels)\n                \n                # total correct of labels\n                correct += (predicted == labels).sum()\n                \n            accuracy = 100 * correct / float(total)\n            \n            # store loss and iteration\n            loss_list.append(loss.data)\n            iteration_list.append(count)\n            \n        if count % 500 == 0:\n            # print loss\n            print('iteration: {} loss:{} accuracy: {}'.format(count, loss.data, accuracy))","metadata":{"execution":{"iopub.status.busy":"2022-03-02T16:07:28.190816Z","iopub.execute_input":"2022-03-02T16:07:28.191504Z","iopub.status.idle":"2022-03-02T16:08:00.220250Z","shell.execute_reply.started":"2022-03-02T16:07:28.191458Z","shell.execute_reply":"2022-03-02T16:08:00.219403Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"# visualization\nplt.plot(iteration_list, loss_list)\nplt.xlabel(\"number of iteration\")\nplt.ylabel(\"loss\")\nplt.title(\"logistic regression: loss vs number of iteration\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-02T16:08:00.221849Z","iopub.execute_input":"2022-03-02T16:08:00.222126Z","iopub.status.idle":"2022-03-02T16:08:00.423423Z","shell.execute_reply.started":"2022-03-02T16:08:00.222086Z","shell.execute_reply":"2022-03-02T16:08:00.422440Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"markdown","source":"# Artifical neural network","metadata":{}},{"cell_type":"code","source":"# Import Libraries\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable","metadata":{"execution":{"iopub.status.busy":"2022-03-02T16:08:00.424872Z","iopub.execute_input":"2022-03-02T16:08:00.425173Z","iopub.status.idle":"2022-03-02T16:08:00.430205Z","shell.execute_reply.started":"2022-03-02T16:08:00.425132Z","shell.execute_reply":"2022-03-02T16:08:00.429267Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"# create ann model\nclass ANNModel(nn.Module):\n    \n    def __init__(self, input_dim, hidden_dim, output_dim):\n        super(ANNModel, self).__init__()\n        \n        #linear function 1: 785 --> 150\n        self.fc1 = nn.Linear(input_dim, hidden_dim)\n        #Non linearity\n        self.relu1=nn.ReLU()\n        \n        # linear function 2: 150 --> 150\n        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n        # Non-linearity 2\n        self.tanh2 = nn.Tanh()\n        \n        # Linear function 3: 150 --> 150\n        self.fc3 = nn.Linear(hidden_dim, hidden_dim)\n        # Non-linearity 3\n        self.elu3 = nn.ELU()\n        \n        # Linear function 3: 150 --> 10\n        self.fc4 = nn.Linear(hidden_dim, output_dim)\n        \n        \n    def forward(self, x):\n        #linear function 1\n        out = self.fc1(x)\n        # Non-linearity 1\n        out = self.relu1(out)\n        \n        # Linear function 2\n        out = self.fc2(out)\n        # Non-linearity 2\n        out = self.tanh2(out)\n        \n        # linear function 3\n        out = self.fc3(out)\n        # Non-linearity 2\n        out = self.elu3(out)\n        \n        # linear fuction 4(readout)\n        out = self.fc4(out)\n        return out\n    \n    \n# instantiate ANN\ninput_dim = 28*28\nhidden_dim = 150\noutput_dim = 10\n\n#create ann\nmodel = ANNModel(input_dim, hidden_dim, output_dim)\n\n# cross entropy loss\nerror = nn.CrossEntropyLoss()\n\n# SGD optimizer\nlearning_rate = 0.02\noptimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n        ","metadata":{"execution":{"iopub.status.busy":"2022-03-02T16:08:00.432005Z","iopub.execute_input":"2022-03-02T16:08:00.432729Z","iopub.status.idle":"2022-03-02T16:08:00.449001Z","shell.execute_reply.started":"2022-03-02T16:08:00.432683Z","shell.execute_reply":"2022-03-02T16:08:00.448276Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"# ann model training\ncount = 0\nloss_list = []\niteration_list = []\naccuracy_list = []\nfor epoch in range(num_epochs):\n    for i, (images, labels) in enumerate(train_loader):\n        \n        train = Variable(images.view(-1, 28*28))\n        labels = Variable(labels)\n        \n        #clear gradients\n        optimizer.zero_grad()\n        \n        #forward propagation\n        outputs = model(train)\n        \n        # calculate softmax nad cross entropy loss\n        loss = error(outputs, labels)\n        \n        # calculate gradients\n        loss.backward()\n        \n        #update parameters\n        optimizer.step()\n        \n        count += 1\n        \n        if count % 50 == 0:\n            #calculate accuracy\n            correct = 0\n            total = 0\n            # predict test dataset\n            for images, labels in test_loader:\n                \n                test = Variable(images.view(-1, 28*28))\n                \n                # forward propagation\n                outputs = model(test)\n                \n                #get prediction from maximum values\n                predicted = torch.max(outputs.data, 1)[1]\n                \n                # total number of label\n                total += len(labels)\n                \n                # total correct predictions\n                correct += (predicted == labels).sum()\n                \n            accuracy = 100 * correct / float(total)\n            \n            # store loss and iteration\n            loss_list.append(loss.data)\n            iteration_list.append(count)\n            accuracy_list.append(accuracy)\n         \n        if count % 500 == 0:\n            #print loss\n            print('iteration: {} loss: {}  accuracy: {}%'.format(count, loss.data, accuracy))","metadata":{"execution":{"iopub.status.busy":"2022-03-02T16:08:00.450771Z","iopub.execute_input":"2022-03-02T16:08:00.451511Z","iopub.status.idle":"2022-03-02T16:09:04.068235Z","shell.execute_reply.started":"2022-03-02T16:08:00.451467Z","shell.execute_reply":"2022-03-02T16:09:04.067517Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"# visualization loss\nplt.plot(iteration_list, loss_list)\nplt.xlabel(\"Number of iteration\")\nplt.ylabel(\"Loss\")\nplt.title(\"ANN: Loss vs Number of iteration\")\nplt.show()\n\n\n# visualization accuracy\nplt.plot(iteration_list, accuracy_list, color=\"red\")\nplt.xlabel(\"Number of iteration\")\nplt.ylabel(\"Accuracy\")\nplt.title(\"ANN: Accuracy vs Number of iteration\")\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2022-03-02T16:09:04.069848Z","iopub.execute_input":"2022-03-02T16:09:04.070457Z","iopub.status.idle":"2022-03-02T16:09:04.458222Z","shell.execute_reply.started":"2022-03-02T16:09:04.070411Z","shell.execute_reply":"2022-03-02T16:09:04.456936Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"markdown","source":"# Convolutional Neural Network(CNN)","metadata":{}},{"cell_type":"code","source":"# Import Libraries\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable","metadata":{"execution":{"iopub.status.busy":"2022-03-02T16:09:04.460046Z","iopub.execute_input":"2022-03-02T16:09:04.461043Z","iopub.status.idle":"2022-03-02T16:09:04.466329Z","shell.execute_reply.started":"2022-03-02T16:09:04.460992Z","shell.execute_reply":"2022-03-02T16:09:04.465333Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"# create CNN model\nclass CNNModel(nn.Module):\n    def __init__(self):\n        super(CNNModel, self).__init__()\n        \n        # convolution 1\n        self.cnn1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=5, stride=1, padding=0)\n        self.relu1 = nn.ReLU()\n        \n        # max pool 1\n        self.maxpool1 = nn.MaxPool2d(kernel_size=2)\n        \n        # convolution 2\n        self.cnn2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5, stride=1, padding=0)\n        self.relu2 = nn.ReLU()\n        \n        # max pool 2\n        self.maxpool2 = nn.MaxPool2d(kernel_size=2)\n        \n        # fully connected 1\n        self.fc1 = nn.Linear(32 * 4 * 4, 10)\n        \n    \n    def forward(self, x):\n        #convolution 1\n        out = self.cnn1(x)\n        out = self.relu1(out)\n        \n        #max pool 1\n        out = self.maxpool1(out)\n        \n        # convolution 2\n        out = self.cnn2(out)\n        out = self.relu2(out)\n        \n        # max pool 2\n        out = self.maxpool2(out)\n        \n        # faltten\n        out = out.view(out.size(0), -1)\n        \n        # linear function (readout)\n        out = self.fc1(out)\n        \n        return out\n    \n    \n# batch size, epoch, iteration\nbatch_size = 100\nn_iters = 2500\nnum_epochs = n_iters / (len(features_train) / batch_size)\nnum_epochs = int(num_epochs)\n\n# pytorch train and test sets\ntrain = torch.utils.data.TensorDataset(featuresTrain, targetsTrain)\ntest = torch.utils.data.TensorDataset(featuresTest, targetsTest)\n\n# data loader\ntrain_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=False)\ntest_loader = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=False)\n\n# create cnn\nmodel = CNNModel()\n\n# cross entropy loss\nerror = nn.CrossEntropyLoss()\n\n# sgd optimizer\nlearning_rate = 0.1\noptimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)","metadata":{"execution":{"iopub.status.busy":"2022-03-02T16:09:04.467758Z","iopub.execute_input":"2022-03-02T16:09:04.468014Z","iopub.status.idle":"2022-03-02T16:09:04.487861Z","shell.execute_reply.started":"2022-03-02T16:09:04.467983Z","shell.execute_reply":"2022-03-02T16:09:04.486771Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"#CNN model training\ncount = 0\nloss_list = []\niteration_list = []\naccuracy_list = []\nfor epoch in range(num_epochs):\n    for i, (images, labels) in enumerate(train_loader):\n        \n        train = Variable(images.view(100,1,28,28))\n        labels = Variable(labels)\n        \n        # Clear gradients\n        optimizer.zero_grad()\n        \n        # Forward propagation\n        outputs = model(train)\n        \n        \n        # Calculate softmax and ross entropy loss\n        loss = error(outputs, labels)\n\n        # calculate gradients\n        loss.backward()\n        \n        # update parameters\n        optimizer.step()\n        \n        count += 1\n        \n        if count % 50 == 0:\n            # calculate accuracy\n            correct = 0\n            total = 0\n            # iterate through test dataset\n            for images, labels in test_loader:\n                \n                test = Variable(images.view(100,1,28,28))\n                \n                # forward propagation\n                outputs = model(test)\n                \n                # get predictions from the maximum value\n                predicted = torch.max(outputs.data, 1)[1]\n                \n                # total number of labels\n                total += len(labels)\n                \n                correct += (predicted == labels).sum()\n                \n        accuracy = 100 * correct / float(total)\n        \n        # store loss and iteration\n        loss_list.append(loss.data)\n        iteration_list.append(count)\n        accuracy_list.append(accuracy)\n    if count % 500 == 0:\n        # print loss\n        print('iteration:{} loss: {} accuracy: {}%'.format(count, loss.data, accuracy))","metadata":{"execution":{"iopub.status.busy":"2022-03-02T16:09:04.489624Z","iopub.execute_input":"2022-03-02T16:09:04.490194Z","iopub.status.idle":"2022-03-02T16:10:25.528237Z","shell.execute_reply.started":"2022-03-02T16:09:04.490139Z","shell.execute_reply":"2022-03-02T16:10:25.527269Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"# visualization loss \nplt.plot(iteration_list,loss_list)\nplt.xlabel(\"Number of iteration\")\nplt.ylabel(\"Loss\")\nplt.title(\"CNN: Loss vs Number of iteration\")\nplt.show()\n\n# visualization accuracy \nplt.plot(iteration_list,accuracy_list,color = \"red\")\nplt.xlabel(\"Number of iteration\")\nplt.ylabel(\"Accuracy\")\nplt.title(\"CNN: Accuracy vs Number of iteration\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-02T16:10:25.532456Z","iopub.execute_input":"2022-03-02T16:10:25.533035Z","iopub.status.idle":"2022-03-02T16:10:26.248224Z","shell.execute_reply.started":"2022-03-02T16:10:25.532994Z","shell.execute_reply":"2022-03-02T16:10:26.247528Z"},"trusted":true},"execution_count":72,"outputs":[]}]}